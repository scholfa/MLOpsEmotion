version: "3.9"

services:
  # Your Streamlit App
  app:
    build:
      context: .
      dockerfile: Dockerfile
    image: mlopsemotion-app
    env_file:
      - .env
    working_dir: /app
    volumes:
      - app-data:/app/data
    ports:
      - "8501:8501"
    depends_on:
      - mlflow
      - prefect
    environment:
      - PREFECT_API_URL=http://prefect:4200/api
    command: >
      streamlit run app/streamlit_app.py
      --server.port=8501
      --server.enableCORS=false
      --server.enableXsrfProtection=false

  # Prefect Server (UI/API)
  prefect:
    image: docker.io/prefecthq/prefect:3.4.0-python3.12
    ports:
      - "4200:4200"
    environment:
      - PREFECT_UI_URL=http://localhost:4200
    entrypoint: ["prefect", "server", "start"]
    volumes:
      - app-data:/app/data

  # Prefect Worker
  prefect-worker:
    image: docker.io/prefecthq/prefect:3.4.0-python3.12
    working_dir: /shared
    volumes:
      - app-shared:/shared:ro
      - app-data:/app/data
    depends_on:
      - prefect
    environment:
      - PREFECT_API_URL=http://prefect:4200/api
    command: >
      sh -c "
      prefect deploy prefect.yaml &&
      prefect worker start --pool 'default-pool'"

  # MLflow Tracking Server
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.22.0
    ports:
      - "5000:5000"
    environment:
      - MLFLOW_TRACKING_URI=http://0.0.0.0:5000
    volumes:
      - app-data:/app/data

  # PyTorch-based inference container
  inference:
    image: docker.io/pytorch/pytorch:2.6.0-cuda12.4-cudnn9-runtime
    working_dir: /app
    volumes:
      - app-shared:/app/shared:ro
      - app-data:/app/data
    command: tail -f /dev/null

  # Init container to copy flows + config to shared volume
  init-shared:
    image: alpine
    volumes:
      - app-shared:/shared
      - .:/source:ro,z
    entrypoint: ["/bin/sh", "-c"]
    command: >
      "mkdir -p /shared/flows &&
       cp -r /source/flows /shared &&
       cp /source/prefect.yaml /shared"

volumes:
  app-data:
  app-shared:
